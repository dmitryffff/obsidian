---
tags:
  - backend
  - postgresql
  - database_indexes
Источник: https://www.youtube.com/watch?v=ju9F8OvnL4E
Дата: 2024-09-15
оценка(0/10): 8
---
### Резюме
Интересный доклад. Немного долгий, поэтому даже на 1.5 смотрится отлично. Мне дал понимание того, как выглядит b-tree индексы, вот это дерево. А так же базовое понимание чтения планировщика, статистики. Узнал некоторые "тонкие", не самые популярные особенности pgsql, по типу статистики по сэмплу из 30 000 строк и т.п. **Замечательно, что есть примеры конкретных запросов и конкретных индексов, это великолепно.** 

## Необходимая для начала информация

1. OLTP нагрузка(web, api и т.п.) – операции, которые должны отдавать максимально быстрые ответы(укладываться в миллисекунды), такие как запросы пользователей на api.
2. OLAP нагрузка – аналитическая, большие аналитические запросы на большом объеме данных.
3. Индекс – 
	1. (оф.)структура данных, которая улучшает скорость операций поиска и извлечения данных из таблицы.
	2. (прост.)костыль, для ускорения.
4. Во что обходятся нам индексы:
	1. **Замедление записи в бд**. Помимо записи самой строки, нам надо будет создать индекс и встроить его в существующую структуру индексов. *Для реляционных бд >= 80% чтения,  <=20% запись*.
	2. Дополнительные объемы дискового пространства. *Нормально, когда объяем индексов – половина объяема таблицы*.
	3. Усложнение технического обслуживания. *PG не изменяет строки, а добавляет новые версии строк. Через какое-то время приходит vacuum и удаляет старые строки. Так же происходит и с индексами, но это работает хуже, поэтому может оставаться пустое пространство в памяти – bloat("распухание") индексов. Из-за этого нужно переодически удалять и создавать индексы заново.*
5. Не все индексы полезны. Нужно думать, какие создаешь.
6. Плохой запрос – не всегда медленный. Плохой запрос – много неоптимизированных.
7. Нужна статистика запросов. Можно использовать [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) или [pgBadger](https://github.com/darold/pgbadger)⚠️. *pgBadger анализирует только логи, но в логах(по-умолчанию) выдаются не все запросы, а только те, что медленнее 100мс => у нас не вся статистика.*
8. Для понимая нужно:
	1. Уметь читать планировщик. *Планировщик запросов перебирает различные варианты, комбинации выбора данных и выбирает наименее худший по стоимости(cost). При составлении запросов опирается на статистику(по-умолчанию, 30 000 записей из таблицы).*
	2. Смотреть статистику по таблице в pg_stats(чтобы понимать, на что планировщик смотрит при построении плана):
		1. 
		2. n_distinct – уникальность значений в колонке
		3. correlation – упорядоченность значений(отсортированность)
		4. null_frac – количество пустых значений
		5. most_common_vals, most_common_freqs – наиболее часто встречающиеся значения и частота встречи значения соответственно(массивы)
9. Типы индексов:
	1. **b-tree**
		1. ***Подходят для сравнения(>, <) и равенства(=)***
		2. Самый распространенный тип
		3. Алгоритмы, структуры хранения близки к совершенству
		4. Покрывает 90% задач
		5. Легко создать, ориентируясь на статистику
	2. hash
		1. ***Используется только при равенстве***
		2. В pg бесполезен, b-tree быстрее даже для равенства
	3. gist
		1. Для гео-данных: расстояния, пересечения площадей и т.п.
		2. Расширение ***pg_trgm*** помогает индексировать текстовые запросы для поиска с `like`
		3. Расширение ***btree_gist*** помогает с contains интервалов времени
	4. gin
		1. Может сильно замедлить запись в таблицу из-за сложности создания индекса и встройки его в существующую структуру
		2. Отлично подходит для поиска по jsonb. Может создаваться с одним из параметров:
			1. jsonb_ops(по-умолчанию) – индексирует и ключи, и значения
			2. jsonb_path_ops – индексирует только ключи и, соответсвенно, имеет меньший размер
	5. **brin**
		1. *Т.к. бд работает с блоками данных в таблице(какая-то выборка строк), то мы можем проиндексировать только наименьшее и наибольшее значения в блоке*.
		2. ***Крайне компактный индекс***
		3. ***Только для упорядоченных данных(correlation = 1 в pg_stat**).*
10. Для `primary key` postgresql автоматически создает b-tree индекс.
## Оптимизация

Таблица для примера:
```sql
column        | type             | nullable
--------------+------------------+---------
id            | bigint           | not null
fk_id         | bigint
state         | text
amount        | numeric
item          | text
created_at    | timestamptz
```

1. ***Всегда создавай индексы на `foreign keys`.***
```sql
delete from pgconf where id = 10;

----- Вывод планировщика
Delete on pgconf 
	-> Index Scan using pgconf_pkey on pgconf
		Index Cond: (id = 10)
	Planning Time: 0.043 ms
	Trigger for constraint pgconf_fk_id_fkey: time=690.455 calls=1 <-- *
Execution Time: 690.515 ms
-----

* Здесь основная проблема запроса!! Из-за отсутствия индексов на fk_id при удалении мы последовательно проходимся по всей таблице и ищем, есть ли элемент с таким id?

create index fk on pgconf (fk_id);

----- Вывод планировщика
Delete on pgconf ->
	Index Scan using pgconf_pkey on pgconf
		Index Cond: (id = 10)
	Planning Time: 0.063 ms
	Trigger for constraint pgconf_fk_id_fkey: time=0.047 calls=1
Execution Time: 0.101 ms
-----
```
2. ***Чем меньше индекс, тем меньше времени займет проход по нему pg и тем быстрее мы получим результат!*** Это заметно на больших объемах данных, а, следовательно, и больших размерах индексов.
```sql
-- Смотрим на количество пустых значений(null_frac) в таблице в колонке fk_id
select * from pg_stats where tablename = 'pgconf' and attname = 'fk_id';

----- pg_stats
tablename | pgconf
attname | fk_id
null_frac | 0.92943335 <-- *
n_distinct | -0.070566654
most_common_vals |
most_common_freqs |
correlation | 0.0095442245
-----

* Видими, что 93% значений пустые!!! Следовательно, зачем нам создавать индекс по всем строкам fk_id, если можем создать только для тех, у которых fk_id не равен null

create index fk_not_null on pgconf (fk_id)
	where fk_id is not null;

----- Вывод планировщика
Delete on pgconf
	-> Index Scan using pgconf_pkey on pgconf
		Index Cond: (id = 10)
	Planning Time: 0.069 ms
	Trigger for constraint pgconf_fk_id_fkey: time=0.044 calls=1
Execution Time: 0.100 ms
-----

Результаты по скорости не особо изменились, но мы уменьшили размер индекса в 14 раз!!!!

Time: 690.713 ms vs 0.336 ms
-- Ускорение в 2055 раз!
pgconf_pkey : 214 MB fk : 215 MB fk_not_null : 15 MB 
-- Уменьшение размеров в 14 раз!
```
3. ***Для OLTP нагрузки НЕЛЬЗЯ включать параллельное выполнение.*** Нужно писать запрос так, чтобы он максимально быстро выполнялся на 1-м потоке. Если используем несколько потоков для одного OLTP запроса, то забираем ресурсы у другого запроса.
4. ***Лучше указывать первым полем индекса поле, с большей уникальностью(n_distinct), а последующими по уменьшению(но это не аксиома).*** Иногда, если количество уникальных значений в целом не много, как, например, в поле status – можем в целом не указывать его для индексирования, т.к. будет всего 1-3 "листа" [b-tree дерева](https://ru.wikipedia.org/wiki/B-%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE).
   ![[b-tree дерево.png|400]]
```sql
select * from pgconf
	where state = 'ожидает'
	order by created_at
	limit 100;

----- Вывод планировщика
Limit
	-> Gather Merge
		Workers Planned: 2
		Workers Launched: 2
		-> Sort
			Sort Key: created_at
			Sort Method: top-N heapsort Memory: 35kB
			Worker 0: Sort Method: top-N heapsort Memory: 35kB
			Worker 1: Sort Method: top-N heapsort Memory: 35kB
			-> Parallel Seq Scan on pgconf
				Filter: (state = 'ожидает'::text)
				Rows Removed by Filter: 3003483
Planning Time: 0.140 ms
Execution Time: 362.268 ms
-----

create index normal on pgconf (created_at, state);

----- Вывод планировщика
Limit
	-> Index Scan using normal on pgconf
		Index Cond: (state = 'ожидает'::text)
Planning Time: 0.107 ms
Execution Time: 0.138 ms
-----

----- pg_stats
attname | created_at
null_frac | 0
n_distinct | -0.4638518 <-- *
most_common_vals |
most_common_freqs |
histogram_bounds | {...}
correlation | 1 <-- **
-----

* Хорошая уникальность значений
** Распределение. 1 значит, что все значения отсортированы(с увеличением id увеличивется и время создания)

----- pg_stats
attname | state
null_frac | 0
n_distinct | 3 <-- ***
most_common_vals | {обработано,ожидает,ошибка} <-- ****
most_common_freqs | {0.89863336,0.09996667,0.0014} <-- *****
correlation | 0.81656545
-----

*** У нас в таблице всегда 3 уникальных значения: обработано,ожидает,ошибка
****/***** Распределение значений. Больше всего – "обработано". Если мы хотим заново обработать "ошибка" или впервые "ожидает", то нас не будут интересовать строки с "обработано", можем их не индексировать

create index perfect on pgconf (created_at)
	where state != 'обработано';
ИЛИ
create index perfect on pgconf (created_at, status)
	where state != 'обработано';

----- Вывод планировщика
Limit
	-> Index Scan using perfect on pgconf
		Filter: (state = 'ожидает'::text)
		Rows Removed by Filter: 2
Planning Time: 0.120 ms
Execution Time: 0.105 ms
-----

Time: 690.713 ms vs 0.105 ms
-- Ускорение в 3450 раз!
pgconf_pkey : 214 MB
normal : 464 MB <-
perfect : 21 MB <-
-- Уменьшение размеров в 22 раза!
```
5. Можем добавить "листу" индекса какое-то доп значение, которое не будет отсортировано, а будет просто "висеть" рядом с индексом
```sql
select sum (amount) from pgconf
	where state = 'обработано'
	and item = 'апельсин'
	and created_at between '2021-10-23 00:00'
	                   and '2021-10-24 00:00';

create index special on pgconf (created_at, item)
	include (amount) where state = 'обработано'; <-- *

* include просто добавляет аттрибут к "листу" дерева

----- Вывод планировщика
Aggregate
	-> Index Only Scan using special on pgconf
		Index Cond: ((created_at >= '2021-10-23 00:00') AND
					(created_at <= '2021-10-24 00:00')  AND
					(item = 'апельсин'::text))
		Heap Fetches: 28624
Planning Time: 0.144 ms
Execution Time: 30.084 ms
-----
```